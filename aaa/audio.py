import pyaudio
import numpy as np
from faster_whisper import WhisperModel
from scipy.signal import resample
# zeroitihantei.pyãƒ•ã‚¡ã‚¤ãƒ«ãŒåˆ¥é€”å¿…è¦ã§ã™
# ç„¡éŸ³æ¤œå‡ºã«ä½¿ç”¨ã•ã‚Œã‚‹ãŸã‚ã€ã“ã®importã¯ç¶­æŒã—ã¾ã™
from zeroitihantei import zeroiti

# éŒ²éŸ³è¨­å®š
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 48000  # éŒ²éŸ³ãƒ¬ãƒ¼ãƒˆã¯48000Hzã®ã¾ã¾
SEGMENT_DURATION = 10  # 10ç§’ã”ã¨ã«æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚’å®Ÿè¡Œ
THRESHOLD = 0.1  # éŸ³é‡ã®æœ€å¤§å€¤ã®é–¾å€¤

def record_and_transcribe(stream) -> str:
    """
    ãƒã‚¤ã‚¯ã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éŒ²éŸ³ã—ã€3å€é€Ÿå‡¦ç†ã§æ–‡å­—èµ·ã“ã—ã‚’è¡Œã†é–¢æ•°ã€‚
    """
    # Whisperãƒ¢ãƒ‡ãƒ«ã®æº–å‚™
    # CPUã§ã®å®Ÿè¡Œã¯éå¸¸ã«æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€GPUãŒã‚ã‚Œã°device="cuda"ã‚’æ¨å¥¨ã—ã¾ã™ã€‚
    model = WhisperModel("large-v3", device="cpu", compute_type="float32")

    frames = []
    full_transcription = ''

    # WhisperãŒæ¨å¥¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
    WHISPER_RATE = 16000

    # --- 3å€é€Ÿå‡¦ç†ã®ãŸã‚ã®å›ºå®šè¨­å®š ---
    speed_factor = 3.0
    # Whisperã«ã€Œ3å€é€Ÿã§éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ã€ã ã¨èªè­˜ã•ã›ã‚‹ãŸã‚ã®å½ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
    fake_sample_rate = int(RATE * speed_factor)
    print(f"ğŸš€ é«˜é€ŸåŒ–ãƒ¢ãƒ¼ãƒ‰: Whisperã« {fake_sample_rate}Hz ã®éŸ³å£°ã¨ã—ã¦æ¸¡ã—ã¾ã™ (å®Ÿè³ª3å€é€Ÿå‡¦ç†)")
    # --------------------------

    while True:
        # 10ç§’åˆ†ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’éŒ²éŸ³
        # æ³¨æ„: å®Ÿéš›ã«éŒ²éŸ³ã•ã‚Œã‚‹å®Ÿæ™‚é–“ã¯SEGMENT_DURATION (10ç§’) ã§ã™
        for _ in range(0, int(RATE * SEGMENT_DURATION / CHUNK)):
            data = stream.read(CHUNK, exception_on_overflow=False)
            frames.append(data)

        segment_data = b''.join(frames)
        # numpyãƒãƒƒãƒ•ã‚¡ã«å¤‰æ›
        buffer = np.frombuffer(segment_data, dtype=np.int16).astype(np.float32) / 32768.0

        # --- 3å€é€Ÿ: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã‚’å½è£…ã—ã¦æ¸¡ã™ ---
        segments, _ = model.transcribe(
            buffer,
            language="ja",
            initial_prompt="ã”æä¾›ã„ãŸã ã„ãŸéŸ³å£°ã‚’ã€ä»¥ä¸‹ã®é€šã‚Šã«æ–‡å­—èµ·ã“ã—ã—ã¾ã™ã€‚",
            vad_filter=True,
            sample_rate=fake_sample_rate # <--- 3å€é€ŸåŒ–ã®è‚
        )
        # -----------------------------------------------

        segments = list(segments)
        print("---")
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯å½è£…ã•ã‚ŒãŸãƒ¬ãƒ¼ãƒˆã«åŸºã¥ãæ™‚é–“ã§ã™ (å®Ÿæ™‚é–“ã§ã¯ãªã„)
        for segment in segments:
            # å®Ÿéš›ã®æ™‚é–“ã¯ segment.start / speed_factor ã§è¨ˆç®—ã§ãã¾ã™
            print(f"[å½è£…æ™‚é–“: {segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}")

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
        if len(segments) >= 2:
            for segment in segments[:-1]:
                if segment.text not in full_transcription:
                    full_transcription += segment.text

            # æœ€å¾Œã®æœªå‡¦ç†ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¾ã§æˆ»ã‚‹ (ãƒãƒƒãƒ•ã‚¡å‰Šé™¤)
            last_processed_time = segments[-2].end

            # å½è£…ã•ã‚ŒãŸæ™‚é–“ (3x) ã‚’å®Ÿéš›ã®å‡¦ç†æ™‚é–“ (1x) ã«æˆ»ã™
            actual_processed_time = last_processed_time / speed_factor

            # å®Ÿéš›ã®å‡¦ç†æ™‚é–“ã‹ã‚‰ã€48000Hzã®å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—
            last_processed_frame_index = int(actual_processed_time * WHISPER_RATE / (RATE / CHUNK)) * CHUNK

            # éŒ²éŸ³ãƒãƒƒãƒ•ã‚¡ã®å…ˆé ­ã‹ã‚‰ã€ã™ã§ã«å‡¦ç†ã—ãŸåˆ†ã‚’å‰Šé™¤
            del frames[:last_processed_frame_index]

        # ç„¡éŸ³åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
        renzokuzero = zeroiti(segment_data, RATE, 0.01, THRESHOLD)
        if 1 not in renzokuzero:
            print("ç„¡éŸ³ãŒé€£ç¶šã—ã¾ã—ãŸã€‚éŒ²éŸ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            break

    # æœ€çµ‚ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å‡¦ç†
    if frames:
        segment_data = b''.join(frames)
        buffer = np.frombuffer(segment_data, dtype=np.int16).astype(np.float32) / 32768.0

        num_samples_resampled = int(buffer.shape[0] * (WHISPER_RATE / RATE))
        resampled_buffer = resample(buffer, num_samples_resampled)

        segments, _ = model.transcribe(
            resampled_buffer,
            language="ja",
            sample_rate=fake_sample_rate # <--- ã“ã“ã§ã‚‚å½è£…ãƒ¬ãƒ¼ãƒˆã‚’æ¸¡ã™
        )
        for segment in segments:
            if segment.text not in full_transcription:
                full_transcription += segment.text

    return full_transcription

if __name__ == "__main__":
    import sys

    # scipyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    try:
        import scipy
    except ImportError:
        print("scipyãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™ã€‚`pip install scipy` ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    audio = pyaudio.PyAudio()
    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)

    print("éŒ²éŸ³é–‹å§‹... (Ctrl+Cã§çµ‚äº†)")
    print("æœ¬ã‚³ãƒ¼ãƒ‰ã¯3å€é€Ÿå‡¦ç†ã§å›ºå®šã•ã‚Œã¦ã„ã¾ã™ã€‚")

    # modeå¼•æ•°ã®ãƒã‚§ãƒƒã‚¯ã‚’å‰Šé™¤ã—ã€ç›´æ¥é–¢æ•°ã‚’å‘¼ã³å‡ºã—
    transcription = record_and_transcribe(stream)

    stream.stop_stream()
    stream.close()
    audio.terminate()

    print("\n---æœ€çµ‚çš„ãªæ–‡å­—èµ·ã“ã—çµæœ (3å€é€Ÿå‡¦ç†)---")
    print(transcription)
    print("----------------------------------------\n")